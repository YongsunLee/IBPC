본 논문에서는 많은 수의 파티클 간의 실시간 충돌 알고리즘을 제안한다. 
In this paper, a large number of particles proposes a real-time collision algorithm.

제안된 알고리즘은 삼차원 파티클 위치 정보를 2차원 이미지에 투사하고 이를 기반으로 충돌 처리를 수행하는 단계와 실제 렌더링을 수행하는 두단계를 거친다. 
The proposed algorithm goes through two steps of projecting three-dimensional particle location information into a two-dimensional image and performing collision processing based on it and performing actual rendering.

첫 단계에선 파티클 간의 충돌처리를 수행하며 위치를 업데이트 한다. 
In the first stage, collision processing between particles is performed and the position is updated.

이때 사용되는 데이터는 파티클의 3차원 월드 공간 위치(World Space Position)을 저장한 2차원 형태의 텍스처이며 이를 충돌 감지 텍스처(Collision Detection Texture)라 칭한다. 
The data used at this time is a two-dimensional texture that stores the particle's three-dimensional world space position, and this is called a collision detection texture.

각 파티클의 충돌 처리를 위해서 해당 파티클의 투영 결과를 기반으로 텍스처 좌표를 계산하고 이 좌표를 기준으로 충돌 감지 텍스처를 샘플링하여 파티클의 3차원 위치 값을 읽어온다. 
For collision processing of each particle, texture coordinates are calculated based on the projection result of the particle, and collision detection texture is sampled based on these coordinates to read the particle 3D position value.

충돌 감지 텍스처는 파티클의 3차원 정보를 투영하여 얻는 2차원 투영 좌표를 기반으로 업데이트 되기 때문에 앞서 얻은 텍스처 좌표의 주변을 주어진 범위 내에서 샘플링하면 주변에 존재하는 파티클들의 위치 정보를 얻을 수 있다. 
Since the collision detection texture is updated based on the 2D projection coordinates obtained by projecting the 3D information of the particle, sampling the periphery of the previously obtained texture coordinates within a given range can obtain the location information of the particles present in the periphery.

이 정보를 이용해 현재 파티클과의 충돌처리를 수행하고 처리 후 변화되는 3차원 좌표 형태의 값은 컬러 코드로 변환하여 충돌 감지 텍스처에 업데이트 한다. 
Using this information, collision processing with the current particle is performed, and the values ​​of 3D coordinates that change after processing are converted into color codes and updated in the collision detection texture.

두번째 단계는 첫번째 단계에서 사용된 버퍼를 활용하는 렌더링 패스이다. 
The second stage is a rendering pass that utilizes the buffer used in the first stage.

해당 버퍼는 충돌처리가 끝난 3차원 위치 정보를 가지고 있으며 이를 이용하면 기하 셰이더(Geometry Shader)를 통해 빌보드 형태의 쿼드를 생성할 수 있다. 
The buffer has 3D location information that has been processed for collision, and if you use it, you can create a billboard-shaped quad through a geometry shader.

이 쿼드를 파티클 형태로 렌더링하여 최종 결과를 만들어 낸다. 
This quad is rendered in particle form to produce the final result.

제안된 방법은 파티클당 충돌처리를 O(n) (화면에 존재하는 파티클 개수 * 샘플링하는 텍셀 개수) 복잡도로 끝마칠 수 있다. 결과적으로 실험을 통해서 평균 71ms 이내에 125,000개의 파티클 충돌 처리를 진행할 수 있었다.
The proposed method can end collision processing per particle with O(n) (number of particles in the screen * number of texels to sample) complexity. As a result, we could process 125,000 particle collisions within an average of 71ms.



In this paper, a large number of particles proposes a real-time collision algorithm. The proposed algorithm goes through two steps of projecting three-dimensional particle location information into a two-dimensional image and performing collision processing based on it and performing actual rendering. In the first stage, collision processing between particles is performed and the position is updated. The data used at this time is a two-dimensional texture that stores the particle's three-dimensional world space position, and this is called a collision detection texture. For collision processing of each particle, texture coordinates are calculated based on the projection result of the particle, and collision detection texture is sampled based on these coordinates to read the particle 3D position value. Since the collision detection texture is updated based on the 2D projection coordinates obtained by projecting the 3D information of the particle, sampling the periphery of the previously obtained texture coordinates within a given range can obtain the location information of the particles present in the periphery. Using this information, collision processing with the current particle is performed, and the values ​​of 3D coordinates that change after processing are converted into color codes and updated in the collision detection texture. The second stage is a rendering pass that utilizes the buffer used in the first stage. The buffer has 3D location information that has been processed for collision, and if you use it, you can create a billboard-shaped quad through a geometry shader. This quad is rendered in particle form to produce the final result. The proposed method can end collision processing per particle with O(n) (number of particles in the screen * number of texels to sample) complexity. As a result, we could process 125,000 particle collisions within an average of 71ms.
